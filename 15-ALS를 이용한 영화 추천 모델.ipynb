{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/01 19:13:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/08/01 19:13:13 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# 메모리 용량 설정\n",
    "MAX_MEMORY = '4g'\n",
    "\n",
    "spark = SparkSession.builder.appName(\"movie-recommendation\")\\\n",
    ".config(\"spark.executor.memory\", MAX_MEMORY)\\\n",
    ".config(\"spark.driver.memory\", MAX_MEMORY)\\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-30-105.ap-northeast-2.compute.internal:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>movie-recommendation</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f31b55000d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|    296|   5.0|1147880044|\n",
      "|     1|    306|   3.5|1147868817|\n",
      "|     1|    307|   5.0|1147868828|\n",
      "|     1|    665|   5.0|1147878820|\n",
      "|     1|    899|   3.5|1147868510|\n",
      "|     1|   1088|   4.0|1147868495|\n",
      "|     1|   1175|   3.5|1147868826|\n",
      "|     1|   1217|   3.5|1147878326|\n",
      "|     1|   1237|   5.0|1147868839|\n",
      "|     1|   1250|   4.0|1147868414|\n",
      "|     1|   1260|   3.5|1147877857|\n",
      "|     1|   1653|   4.0|1147868097|\n",
      "|     1|   2011|   2.5|1147868079|\n",
      "|     1|   2012|   2.5|1147868068|\n",
      "|     1|   2068|   2.5|1147869044|\n",
      "|     1|   2161|   3.5|1147868609|\n",
      "|     1|   2351|   4.5|1147877957|\n",
      "|     1|   2573|   4.0|1147878923|\n",
      "|     1|   2632|   5.0|1147878248|\n",
      "|     1|   2692|   5.0|1147869100|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filepath = \"/home/ubuntu/working/spark-examples/data/ml-25m/ratings.csv\"\n",
    "ratings_df = spark.read.csv(f\"file:///{filepath}\", inferSchema=True, header=True)\n",
    "ratings_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#timestamp는 빼고 선택\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "ratings_df = ratings_df.select(F.col(\"userId\"), F.col(\"movieId\"), F.col(\"rating\"))\n",
    "ratings_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|            rating|\n",
      "+-------+------------------+\n",
      "|  count|          25000095|\n",
      "|   mean| 3.533854451353085|\n",
      "| stddev|1.0607439611423535|\n",
      "|    min|               0.5|\n",
      "|    max|               5.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 통계 정보 확인\n",
    "ratings_df.select(F.col(\"rating\")).describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 세트와 테스트 세트 분리\n",
    "train_df, test_df = ratings_df.randomSplit([0.8,0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "als = ALS(\n",
    "    maxIter=5,  #훈련 횟수\n",
    "    regParam=0.1, # 가중치 정규화 계수\n",
    "    userCol=\"userId\", # 사용자 정보 컬럼\n",
    "    itemCol=\"movieId\", # 아이템 컬럼(여기서는 영화)\n",
    "    ratingCol=\"rating\", # 평점 컬럼 \n",
    "    coldStartStrategy='drop'   # 학습하지 못한 데이터에 대한 처리. 여기서는 삭제\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/01 19:46:42 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/08/01 19:46:42 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "23/08/01 19:46:46 WARN InstanceBuilder$NativeLAPACK: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 모델을 훈련하면 모델 객체가 등장\n",
    "als_model = als.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.ml.recommendation.ALS'>\n",
      "<class 'pyspark.ml.recommendation.ALSModel'>\n"
     ]
    }
   ],
   "source": [
    "print(type(als))\n",
    "print(type(als_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 85:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|     1|    307|   5.0|  4.097136|\n",
      "|     1|   1175|   3.5|   4.02484|\n",
      "|     1|   1237|   5.0| 4.0553126|\n",
      "|     1|   2012|   2.5| 2.9603703|\n",
      "|     1|   2692|   5.0| 4.0545907|\n",
      "|     1|   3949|   5.0| 4.0692253|\n",
      "|     1|   4973|   4.5|  4.226791|\n",
      "|     1|   5912|   3.0| 3.8326893|\n",
      "|     1|   7318|   2.0| 2.8871064|\n",
      "|     1|   7323|   3.5|   3.90392|\n",
      "|     1|   7327|   3.5|  3.980063|\n",
      "|     1|   7365|   4.0| 3.7241123|\n",
      "|     1|   7937|   3.0| 3.8105354|\n",
      "|     1|   8014|   3.5| 4.0631304|\n",
      "|     1|   8786|   4.0| 3.7699409|\n",
      "|     1|  32591|   5.0|  3.478232|\n",
      "|     3|      1|   4.0|  3.911788|\n",
      "|     3|    111|   4.0| 4.0194097|\n",
      "|     3|    214|   5.0| 3.9687915|\n",
      "|     3|    293|   5.0| 4.3474517|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 예측을 할때 사이킷 런은 predict 메소드를 사용하지만\n",
    "# 스파크에서는 feature가 들어가서 label이 나오는 데이터의 변환으로 판단 - transform\n",
    "predictions = als_model.transform(test_df)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가(RMSE)\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    predictionCol=\"prediction\",\n",
    "    labelCol=\"rating\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8042175308573307"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/spark-env-324/lib/python3.8/site-packages/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n",
      "[Stage 160:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|     1|[{177209, 5.49970...|\n",
      "|     3|[{177209, 5.73822...|\n",
      "|     5|[{203086, 5.92206...|\n",
      "|     6|[{177209, 6.03870...|\n",
      "|     9|[{185645, 6.58230...|\n",
      "|    12|[{183947, 5.24145...|\n",
      "|    13|[{194434, 6.07480...|\n",
      "|    15|[{183947, 6.57887...|\n",
      "|    16|[{183947, 5.98277...|\n",
      "|    17|[{127252, 5.20187...|\n",
      "|    19|[{194434, 5.39699...|\n",
      "|    20|[{177209, 6.34902...|\n",
      "|    22|[{177209, 6.97918...|\n",
      "|    26|[{177209, 5.30613...|\n",
      "|    27|[{194334, 5.92979...|\n",
      "|    28|[{177209, 7.05149...|\n",
      "|    31|[{185645, 4.05565...|\n",
      "|    34|[{185645, 5.63664...|\n",
      "|    35|[{203086, 5.69996...|\n",
      "|    37|[{183947, 6.08584...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 추천하기 1\n",
    "# 각 user 에게 tip3 아이템(영화) 추천\n",
    "als_model.recommendForAllUsers(3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 189:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|movieId|     recommendations|\n",
      "+-------+--------------------+\n",
      "|      1|[{105130, 5.60369...|\n",
      "|      3|[{87426, 5.426358...|\n",
      "|      5|[{143282, 5.76672...|\n",
      "|      6|[{156318, 5.65070...|\n",
      "|      9|[{87426, 5.298882...|\n",
      "|     12|[{87426, 5.547249...|\n",
      "|     13|[{87426, 5.517051...|\n",
      "|     15|[{87426, 5.302298...|\n",
      "|     16|[{156318, 5.56757...|\n",
      "|     17|[{58248, 5.587661...|\n",
      "|     19|[{87426, 5.598240...|\n",
      "|     20|[{87426, 5.291905...|\n",
      "|     22|[{87426, 5.471110...|\n",
      "|     26|[{156318, 5.14574...|\n",
      "|     27|[{87426, 5.669713...|\n",
      "|     28|[{105801, 5.58554...|\n",
      "|     31|[{87426, 5.495156...|\n",
      "|     34|[{58248, 5.414247...|\n",
      "|     35|[{32202, 4.837688...|\n",
      "|     37|[{87426, 4.989361...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 추천하기 2\n",
    "# 각 영화에 어울리는 top3 유저를 추천\n",
    "als_model.recommendForAllItems(3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 190:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|userId|\n",
      "+------+\n",
      "|   276|\n",
      "|    53|\n",
      "|   393|\n",
      "+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 사용자 목록을 만들어서 추천. 반드시 dataframe으로 만들어서 예측\n",
    "from pyspark.sql.types import IntegerType\n",
    "user_list = [276, 53,393]\n",
    "users_df = spark.createDataFrame(user_list, IntegerType()).toDF(\"userId\")\n",
    "users_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 222:==================================================>(1996 + 2) / 2000]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|    53|[{192089, 6.55530...|\n",
      "|   276|[{177209, 6.78933...|\n",
      "|   393|[{127252, 6.4703}...|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "user_recommend = als_model.recommendForUserSubset(users_df, 5) # 유저 3명에 대해 5개의 영화 추천\n",
    "user_recommend.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 270:==================================================>(1997 + 2) / 2000]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|     recommendations|\n",
      "+--------------------+\n",
      "|[{127252, 6.4703}...|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 특정 user를 위한 추천\n",
    "movies_list = user_recommend.filter(\"userId = 393\").select(\"recommendations\")\n",
    "movies_list.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(recommendations=[Row(movieId=127252, rating=6.470300197601318), Row(movieId=190707, rating=6.36067008972168), Row(movieId=203086, rating=6.168588161468506), Row(movieId=86288, rating=6.057657241821289), Row(movieId=99724, rating=5.908327102661133)])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 프레임으로 조회해서 가져오는 것이 아닌, 실제 데이터를 가져와야 하기 때문에 collect()를 사용하는 것이 좋다.\n",
    "movies_list = movies_list.select(\"recommendations\").collect()\n",
    "movies_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(movieId=127252, rating=6.470300197601318),\n",
       " Row(movieId=190707, rating=6.36067008972168),\n",
       " Row(movieId=203086, rating=6.168588161468506),\n",
       " Row(movieId=86288, rating=6.057657241821289),\n",
       " Row(movieId=99724, rating=5.908327102661133)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_list_first = movies_list[0].recommendations\n",
    "movies_list_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|movieId|           rating|\n",
      "+-------+-----------------+\n",
      "| 127252|6.470300197601318|\n",
      "| 190707| 6.36067008972168|\n",
      "| 203086|6.168588161468506|\n",
      "|  86288|6.057657241821289|\n",
      "|  99724|5.908327102661133|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 추천 테이블\n",
    "recommend_df = spark.createDataFrame(movies_list_first)\n",
    "recommend_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "|      6|         Heat (1995)|Action|Crime|Thri...|\n",
      "|      7|      Sabrina (1995)|      Comedy|Romance|\n",
      "|      8| Tom and Huck (1995)|  Adventure|Children|\n",
      "|      9| Sudden Death (1995)|              Action|\n",
      "|     10|    GoldenEye (1995)|Action|Adventure|...|\n",
      "|     11|American Presiden...|Comedy|Drama|Romance|\n",
      "|     12|Dracula: Dead and...|       Comedy|Horror|\n",
      "|     13|        Balto (1995)|Adventure|Animati...|\n",
      "|     14|        Nixon (1995)|               Drama|\n",
      "|     15|Cutthroat Island ...|Action|Adventure|...|\n",
      "|     16|       Casino (1995)|         Crime|Drama|\n",
      "|     17|Sense and Sensibi...|       Drama|Romance|\n",
      "|     18|   Four Rooms (1995)|              Comedy|\n",
      "|     19|Ace Ventura: When...|              Comedy|\n",
      "|     20|  Money Train (1995)|Action|Comedy|Cri...|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 영화 메타 데이터 프레임 만들기\n",
    "movie_filepath = \"/home/ubuntu/working/spark-examples/data/ml-25m/movies.csv\"\n",
    "movies_df = spark.read.csv(f\"file:///{movie_filepath}\", inferSchema=True, header=True)\n",
    "movies_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_df.createOrReplaceTempView(\"rec\")\n",
    "movies_df.createOrReplaceTempView(\"movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "|      6|         Heat (1995)|Action|Crime|Thri...|\n",
      "|      7|      Sabrina (1995)|      Comedy|Romance|\n",
      "|      8| Tom and Huck (1995)|  Adventure|Children|\n",
      "|      9| Sudden Death (1995)|              Action|\n",
      "|     10|    GoldenEye (1995)|Action|Adventure|...|\n",
      "|     11|American Presiden...|Comedy|Drama|Romance|\n",
      "|     12|Dracula: Dead and...|       Comedy|Horror|\n",
      "|     13|        Balto (1995)|Adventure|Animati...|\n",
      "|     14|        Nixon (1995)|               Drama|\n",
      "|     15|Cutthroat Island ...|Action|Adventure|...|\n",
      "|     16|       Casino (1995)|         Crime|Drama|\n",
      "|     17|Sense and Sensibi...|       Drama|Romance|\n",
      "|     18|   Four Rooms (1995)|              Comedy|\n",
      "|     19|Ace Ventura: When...|              Comedy|\n",
      "|     20|  Money Train (1995)|Action|Comedy|Cri...|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query=\"\"\"select * from movies\"\"\"\n",
    "spark.sql(query).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+-------+-----------------+\n",
      "|movieId|               title|              genres|movieId|           rating|\n",
      "+-------+--------------------+--------------------+-------+-----------------+\n",
      "| 127252|The Veil of Twili...|Crime|Fantasy|Mys...| 127252|6.470300197601318|\n",
      "| 190707|         1968 (2018)|  (no genres listed)| 190707| 6.36067008972168|\n",
      "| 203086|Truth and Justice...|               Drama| 203086|6.168588161468506|\n",
      "|  86288|Day the Universe ...|         Documentary|  86288|6.057657241821289|\n",
      "|  99724|         K-11 (2012)|         Crime|Drama|  99724|5.908327102661133|\n",
      "+-------+--------------------+--------------------+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "select *\n",
    "from movies\n",
    "join rec on movies.movieId = rec.movieId\n",
    "order by rating desc;\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
